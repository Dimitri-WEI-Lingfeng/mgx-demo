# Timezone (database and services use same TZ)
TZ=Asia/Shanghai

# MongoDB
MONGODB_URL=mongodb://mongodb:27017
MONGODB_DB=mgx

# JWT / OAuth2
JWT_SECRET_KEY=dev-secret-please-change-in-production
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=1440
JWT_ISSUER=mgx-oauth2
JWT_AUDIENCE=mgx

# OAuth2 Provider
OAUTH2_PROVIDER_URL=http://oauth2-provider:8001
JWKS_CACHE_SECONDS=300

# Workspaces
WORKSPACES_ROOT=/workspaces
# Host path for mounting volumes (used when creating dev/agent containers)
# MUST be absolute path - Docker rejects relative paths like ./workspaces
# Local dev: use absolute path e.g. /Users/you/project/workspaces
# docker-compose sets this to ${PWD}/workspaces
HOST_WORKSPACES_ROOT=./workspaces

# Redis / Celery
REDIS_URL=redis://redis:6379/0

# Apisix
APISIX_ADMIN_URL=http://apisix:9180
# 与 infra/apisix/config.yaml 中 deployment.admin.admin_key 保持一致
APISIX_ADMIN_KEY=edd1c9f034335f136f87ad84b625c8f1

# Dev container direct access (browser reaches dev server at dev_external_host:port)
# Local: http://localhost; Remote: http://your-host-ip
DEV_EXTERNAL_HOST=http://localhost

# Default admin user
DEFAULT_ADMIN_USERNAME=admin
DEFAULT_ADMIN_PASSWORD=admin123

# Langfuse Configuration (for LLM observability and tracing)
# Get API keys from https://cloud.langfuse.com or your self-hosted instance
LANGFUSE_PUBLIC_KEY=pk-lf-...
LANGFUSE_SECRET_KEY=sk-lf-...
LANGFUSE_HOST=https://cloud.langfuse.com
LANGFUSE_ENABLED=false

# Agent / MCP - mgx-api 调用配置（Agent 通过 MCP 调用 mgx-api 的 Docker 操作）
# API Key 与 session 绑定：scheduler 创建 agent 容器时注入 MGX_AGENT_API_KEY=session_id
# MCP 端点校验 X-API-Key 对应的 session 是否存在于数据库
# 可选 MGX_AGENT_API_KEY：用于兼容/测试，匹配时也可放行（生产环境可不配置）
# MGX_AGENT_API_KEY=dev-agent-api-key
MGX_API_URL=http://mgx-api:8000
MGX_NETWORK=infra_mgx-network
MGX_MCP_PATH=/mcp

# Agent Container Configuration
# Agent 容器内 workspace 根路径（与 scheduler 挂载的 bind 路径一致，默认 /workspace）
AGENT_WORKSPACE_ROOT_IN_CONTAINER=/workspace
AGENT_CONTAINER_IMAGE=mgx:latest
AGENT_CONTAINER_MEMORY_LIMIT=2g
AGENT_CONTAINER_CPU_QUOTA=100000
AGENT_TASK_TIMEOUT_SECONDS=1800

# LLM API Configuration (required for agent to call LLM)
# OpenAI-compatible API: OpenAI, DashScope (阿里云), OpenRouter, etc.
# For qwen3-coder-flash: use DashScope API key and base URL
OPENAI_API_KEY=sk-xxx
# OPENAI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1  # DashScope 兼容模式

# Agent Team Configuration
# Default model for all agents (can be overridden per agent)
AGENT_DEFAULT_MODEL=gpt-4o-mini
AGENT_DEFAULT_TEMPERATURE=0.7
AGENT_MAX_ITERATIONS=20

# Individual Agent Model Configuration (optional)
# If not set, will use AGENT_DEFAULT_MODEL
# Recommended: use gpt-4o for Architect and Engineer for better quality
# AGENT_ARCHITECT_MODEL=gpt-4o
# AGENT_ENGINEER_MODEL=gpt-4o

# Individual Agent Temperature Configuration (optional)
# AGENT_ARCHITECT_TEMPERATURE=0.3
# AGENT_ENGINEER_TEMPERATURE=0.5

# Context Compression
CONTEXT_COMPRESSION_STRATEGY=sliding_window
CONTEXT_MAX_TOKENS=4000
CONTEXT_RECENT_WINDOW=15
ENABLE_CONTEXT_COMPRESSION=false

# RAG Configuration
ENABLE_RAG=false
VECTOR_STORE_PATH=./vector_stores
RAG_TOP_K=5
ENABLE_RAG_COMPRESSION=true

# Search Configuration
ENABLE_WEB_SEARCH=false
# TAVILY_API_KEY=your-tavily-api-key

# Other
ENABLE_CODE_REVIEW=true
